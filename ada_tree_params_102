(60, 1) 0.001530386740331486
(95, 0.8) 0.0014922048997772696
(65, 1) -0.003751720341315705
(25, 0.8) -0.006174127986816821
(35, 1) -0.0065648224607762285
(20, 0.8) -0.008266483516483545
(70, 1) -0.008298869589192166
(80, 0.8) -0.008702732542092202
(5, 0.8) -0.009665936473165437
(30, 1) -0.009906542056074797
(65, 0.8) -0.010525152017689393
(90, 0.8) -0.011320754716981126
(70, 0.8) -0.013819884329385907
(75, 0.8) -0.01462575674188228
(85, 1) -0.014730439590821117
(85, 0.8) -0.01694736842105263
(45, 0.4) -0.01908841295991213
(75, 1) -0.019163445610160094
(70, 0.4) -0.021211034482758614
(50, 1) -0.021212537805883974
(40, 1) -0.02194452073606151
(95, 0.4) -0.023357360687551974
(5, 0.4) -0.023386301369862986
(80, 0.2) -0.02338922484881806
(10, 0.8) -0.023709986320109448
(40, 0.4) -0.02785439560439563
(75, 0.2) -0.02838789546079785
(95, 1) -0.028871638480731907
(40, 0.2) -0.02969713656387667
(90, 1) -0.030608912261278664
(55, 1) -0.030747869122903483
(45, 1) -0.030822784810126593
(20, 1) -0.031077598025774613
(75, 0.4) -0.031348593491450596
(70, 0.2) -0.0317659983521011
(55, 0.4) -0.032342068965517244
(15, 1) -0.033295890410958845
(60, 0.4) -0.03337282998071098
(90, 0.4) -0.03339523281596448
(20, 0.2) -0.03421182266009847
(85, 0.4) -0.03441468801766976
(65, 0.4) -0.034423925027563376
(15, 0.8) -0.034761904761904744
(80, 1) -0.03505546311702711
(35, 0.8) -0.035400054990376816
(60, 0.8) -0.03592418372993923
(50, 0.2) -0.03634280982611092
(30, 0.2) -0.0375294762818755
(5, 0.6) -0.038126888217522775
(50, 0.4) -0.038381948266373124
(30, 0.8) -0.03881448957189907
(45, 0.8) -0.03885674931129477
(10, 1) -0.040847039473684156
(25, 1) -0.04130494505494505
(85, 0.2) -0.04166712517193948
(80, 0.4) -0.04301855441705899
(40, 0.8) -0.04445331864500143
(65, 0.2) -0.0447332233223322
(45, 0.2) -0.0451022099447513
(25, 0.2) -0.04702110167169082
(55, 0.2) -0.0477162534435261
(35, 0.2) -0.05101206801974765
(50, 0.8) -0.05282362682859506
(55, 0.8) -0.053284611141754076
(35, 0.4) -0.054030794610943095
(95, 0.2) -0.05437499999999992
(60, 0.2) -0.05455518945634262
(90, 0.2) -0.05930967563071801
(15, 0.6) -0.06118066996155951
(95, 0.6) -0.0627851605758582
(20, 0.6) -0.06396816684961584
(15, 0.2) -0.0647993447993447
(30, 0.4) -0.06788435187722663
(5, 1) -0.06879748565181734
(60, 0.6) -0.07258188824662817
(25, 0.6) -0.0751126373626373
(10, 0.6) -0.07525940159209449
(10, 0.4) -0.07556253413435284
(5, 0.2) -0.07566238732586734
(55, 0.6) -0.07720539647577102
(10, 0.2) -0.0783698030634574
(25, 0.4) -0.08078167855183782
(15, 0.4) -0.08198195735374539
(75, 0.6) -0.08272174633876776
(45, 0.6) -0.0856538461538462
(20, 0.4) -0.0864444444444445
(30, 0.6) -0.09005503577325279
(65, 0.6) -0.09074165977391793
(70, 0.6) -0.09291412742382281
(50, 0.6) -0.09871153846153856
(80, 0.6) -0.10347525573679862
(90, 0.6) -0.104607517965727
(40, 0.6) -0.10538419168273205
(35, 0.6) -0.10915319265552226
(85, 0.6) -0.11430743710257132




code:
estimators = list(range(5,100, 5))
learning_rate = [0.2, 0.4, 0.6, 0.8, 1]
params = {'learning_rate': learning_rate, 'n_estimators' : estimators}
params_list = list(ParameterGrid(params))
best_params = dict()

j = 0
for comb in params_list:
    our_tree= tree.DecisionTreeClassifier(min_samples_leaf = 14, min_samples_split=14,
    max_depth = 11, criterion= 'gini', class_weight= {0.0:2.15865, 1.0:3.84336, 2.0:3.61584},
                                 max_features=None, random_state=42)
    clf = AdaBoostClassifier(base_estimator=our_tree, n_estimators=comb['n_estimators'], learning_rate=comb['learning_rate'],
                             random_state=42)
    #clf.fit(games, results)
    clf.fit(best_features, results)
    # if comb['class_weight']  == {0.0:1, 1.0:1, 2.0:1}:
    #     is_weighted = 'umweighted'
    # else:
    #     is_weighted = 'weighted'
    params_tuple = (comb['n_estimators'], comb['learning_rate'])
    print(j)
    print(params_tuple)
    best_params[params_tuple] = play(clf)
    j += 1


sort_orders = sorted(best_params.items(), key=lambda x: x[1], reverse=True)
for i in sort_orders:
      print(i[0], i[1])



default estimator:
(5, 0.8) -0.07335443037974691
(5, 1) -0.07365934065934074
(5, 0.6) -0.07938075313807541
(15, 0.2) -0.08152646239554326
(20, 0.2) -0.08191460055096433
(20, 0.6) -0.08241833653582223
(25, 1) -0.0833132365031516
(30, 0.6) -0.0840203073545555
(35, 0.6) -0.08432647462277097
(35, 1) -0.08461812209143181
(30, 0.2) -0.08503020318506328
(30, 1) -0.08514935598794202
(10, 0.2) -0.08515349630471865
(40, 1) -0.08542567752532175
(40, 0.6) -0.08632921810699595
(70, 0.8) -0.0866611887154205
(50, 0.8) -0.08695258975061669
(25, 0.6) -0.08696487376509339
(85, 1) -0.08696604600219067
(65, 0.8) -0.08696903261167446
(35, 0.8) -0.08708881578947378
(25, 0.4) -0.08730441943453204
(85, 0.4) -0.08735874931431714
(90, 1) -0.08738701725554648
(75, 0.2) -0.08749725576289796
(5, 0.4) -0.08761227970437761
(65, 0.4) -0.08776680384087801
(45, 0.6) -0.0877805212620028
(80, 1) -0.08788335158817094
(35, 0.4) -0.08798298572996714
(50, 0.4) -0.08822996706915487
(60, 0.8) -0.08826027397260278
(65, 0.2) -0.08840285400658625
(10, 0.6) -0.08853571428571436
(70, 0.2) -0.08854006586169051
(60, 0.4) -0.0886172839506174
(55, 0.8) -0.08862702110167174
(70, 0.4) -0.08864471879286703
(75, 1) -0.08883899233296831
(55, 0.4) -0.08886725178277576
(75, 0.4) -0.08905624142661187
(40, 0.4) -0.08913556531284311
(95, 1) -0.08915365653245692
(60, 0.2) -0.08918496158068064
(80, 0.2) -0.08946776406035668
(45, 0.8) -0.08947671232876718
(85, 0.2) -0.08955006858710568
(25, 0.2) -0.08961771177117725
(20, 0.8) -0.08969538968166857
(50, 1) -0.08969863013698637
(90, 0.2) -0.08971467764060363
(95, 0.2) -0.08971467764060363
(20, 0.4) -0.08982147761603965
(45, 0.4) -0.08993139407244793
(15, 0.6) -0.0901317595388417
(90, 0.8) -0.09027108433734946
(85, 0.8) -0.09049274568847529
(80, 0.8) -0.09051218844152294
(10, 1) -0.09052429316497403
(35, 0.2) -0.09056028563581445
(40, 0.2) -0.09060406370126314
(20, 1) -0.09060614371914436
(30, 0.8) -0.0907456140350878
(15, 0.4) -0.09089310250068709
(80, 0.4) -0.09103400987383443
(30, 0.4) -0.09113093604172394
(95, 0.4) -0.09114371914426776
(55, 0.6) -0.09132199670872197
(15, 0.8) -0.0913873626373627
(75, 0.8) -0.09140000000000005
(55, 1) -0.09150684931506854
(55, 0.2) -0.09156104252400557
(70, 0.6) -0.09159396433470515
(45, 0.2) -0.09165019220208684
(70, 1) -0.09179726027397267
(45, 1) -0.09190410958904116
(10, 0.8) -0.0921993410214169
(50, 0.6) -0.09219967087218876
(65, 0.6) -0.09226611796982175
(60, 0.6) -0.09266593527153053
(15, 1) -0.09278113000548553
(50, 0.2) -0.09290340285400667
(65, 1) -0.09292248698986585
(40, 0.8) -0.09303644834201158
(90, 0.4) -0.09322819528250147
(95, 0.8) -0.09339085182141886
(75, 0.6) -0.09347325102880664
(80, 0.6) -0.09461327482172248
(60, 1) -0.09463013698630145
(25, 0.8) -0.09499314505072669
(90, 0.6) -0.09584864272004394
(95, 0.6) -0.0958771929824562
(85, 0.6) -0.09610699588477373
(10, 0.4) -0.09761169332597913
(5, 0.2) -0.10484584060500292



regression estimator:
(90, 0.25) -0.0630269241229264
(80, 0.25) -0.06498232254555354
(40, 0.25) -0.0668370954582541
(50, 0.25) -0.06700027196083773
(30, 0.25) -0.07096546097361996
(70, 0.25) -0.07107424530867563
(60, 0.25) -0.07346750067990217
(20, 0.25) -0.07677726407397349
(40, 0.5) -0.0793608920315476
(50, 0.5) -0.08088115311395169
(30, 0.5) -0.08212945335871646
(80, 0.5) -0.08331520261082415
(90, 0.5) -0.08331520261082415
(60, 0.5) -0.08406309491433245
(70, 0.5) -0.08515093826488995
(10, 1) -0.08568398150666316
(20, 0.5) -0.08914604296981245
(10, 0.75) -0.0901278215936906
(10, 0.5) -0.09155017677454455
(20, 1) -0.09188196899646456
(30, 0.75) -0.09299156921403327
(50, 0.75) -0.09334239869458802
(10, 0.25) -0.09338319282023394
(60, 0.75) -0.09345118302964381
(40, 0.75) -0.09360348109872185
(70, 1) -0.09496056567854239
(50, 1) -0.09704378569486004
(60, 1) -0.09714985042153938
(90, 0.75) -0.09753059559423446
(40, 1) -0.09753331520261091
(90, 1) -0.09759858580364439
(30, 1) -0.09783247212401419
(80, 1) -0.09939080772368787
(80, 0.75) -0.09943432145771008
(70, 0.75) -0.09943432145771014
(20, 0.75) -0.10241501223823782